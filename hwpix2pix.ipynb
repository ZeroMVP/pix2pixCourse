{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Копия блокнота \"HW_NST_pix2pix_CycleGAN.ipynb\"",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Yr7xR_VFKoi"
      },
      "source": [
        "# Домашка \n",
        "---------------------------------------\n",
        "\n",
        "tldr:\n",
        "    \n",
        "* Выбрать архитектуру из рассказанных NST, pix2pix, CycleGAN$^1$\n",
        "* Подберите к ней задачу, чтобы она вам нравилась\n",
        "* Подберите еще одну задачу, которая уже решена (если не NST)\n",
        "* Повторите решение, которое уже есть на вашей архитектуре$^2$ (если не NST)\n",
        "* Выбрать и решите свою задачу$^3$(если не NST)\n",
        "\n",
        "---------------------------------------\n",
        "$^1$: Расположены в порядке возрастания сложности и крутизны\n",
        "\n",
        "\n",
        "$^2$: Поверьте, если вы сделаете этот пункт, следующий будет в *разы* легче\n",
        "\n",
        "$^3$: Выберете задачу, которую никто до вас не решал. Это не должно быть что-то очень сложное, а скорее что-то что вам хочется(и вы успеете) сделать"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiLO2hj1FKok"
      },
      "source": [
        "## Если вы выбрали Neural Style Transfer\n",
        "---------------------------------------\n",
        "Тут все довольно просто на первый и на второй взгляд. Поэтому недостаточно просто написать свою функцию потерь и сдать ноутбук. Если вы хотите приличных баллов, то у вас есть две опции:\n",
        "\n",
        "\n",
        "1. Вы разделяете картинку на две части и переносите на них разные стили. <p><span style=\"color:red\">Нельзя просто взять и два раза применить обычную архитектуру сначала к одной чати картинки, а потом к другой.</span></p> От вас ожидается, что вы отдадите нейросети две картинки стиля и она внутри себя (скорее внутри лосс функции) разделит выходную картинку на две части и к одной части применит один стиль, а к другой - второй. \n",
        "\n",
        "2. Вы переносите *одновременно* два стиля на одну картинку контента.\n",
        "<p><span style=\"color:red\">Нельзя просто взять и два раза применить обычную архитектуру сначала с одним стилем, а потом с другим.</span></p>\n",
        "От вас ожидается, что вы модифицируете модель(скорее лосс модели) для того, чтобы два стиля учитывались с разными весами. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JP1Upi_TFKok"
      },
      "source": [
        "## Если вы выбрали pix2pix\n",
        "---------------------------------------------\n",
        "Здесь от вас ожидается, что вы реализуете свою архитектуру для pix2pix модели. Пожалуйста не копируйте код из открытых репозиториев. Этот факт очень легко обнаружить. Перед тем, как приступить проверьте, что обе задачи, которые вы выбрали влезают на вашу видеокарту или на карту Google Colab. Если они не влезают, но вам все равно очень хочется, то вы можете израсходовать все безплатные триалы облаков (Google, Amazon, .. etc) во вселенной. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNHLFscvFKol"
      },
      "source": [
        "## Если вы выбрали CycleGAN\n",
        "--------------------------------------------\n",
        "Здесь от вас ожидается, что вы реализуете свою архитектуру для CycleGAN модели. Пожалуйста не копируйте код из открытых репозиториев. Этот факт очень легко обнаружить. Перед тем, как приступить проверьте, что обе задачи, которые вы выбрали влезают на вашу видеокарту или на карту Google Colab. CycleGAN в этом смысле хуже, чем pix2pix, он ест больше памяти. Если они не влезают, но вам все равно очень хочется, то вы можете израсходовать все беcплатные триалы облаков (Google, Amazon, .. etc) во вселенной. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yRqgNI_FKom"
      },
      "source": [
        "## Remarks:\n",
        "-----------------------------------------\n",
        "\n",
        "* Это задание нужно для того, чтобы вы наступили на все грабли, что есть. Узнали об их существовании и научились обходить. Посмотрели на неработающие модели и поняли, что все тлен. Изгуглили весь интернет и в конце заставили это все работать. Поверьте, оно того стиот. Не откладывайте это задание на ночь перед сдачей, так как весь смысл \\*пуф\\* улетучится.\n",
        "\n",
        "* У вас два союзника в этой борьбе:\n",
        "    1. Оригинальная статья, те психи, что ее писала как то заставили свою модель работать. Их мысли, которыми они спроводили свое детище, позволят вам написать свой вариант алгоритма. \n",
        "    2. Гугл, он знает ответы на почти все ваши вопросы, но у него есть две ипостаси одна простая в обещении и вы все ее занаете (русскоязычная), а есть еще одна, которая кусается, но знает больше (англоязычная). Если не знаете языва - учите на ходу :)\n",
        "    \n",
        "* На самом деле у вас есть еще один союзник, это ментор проекта (или лектор или семинарист). Его ресурсом нужно пользоваться в ситуации, в которой вы не можете (то есть попытались, и не вышло) найти ответов, используя Гугл и статью.\n",
        "\n",
        "* Сдавать это все нужно следующим образом. Код вы кидаете на github и отправляете ссылку туда, куда вам сказали(в телеграм, степик или еще куда-то)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rJLEx1vxqHr"
      },
      "source": [
        "## Баллы:\n",
        "-----------------------------------------\n",
        "\n",
        "1. Для NST все просто. Вы делаете и у вас на что-то получается. \n",
        "Преподователь смотрит и решает на сколько баллов из 10 это потянет.\n",
        "\n",
        "2. Для остального сложнее. Если вы решили на своей архитектуре задачу, \n",
        "для которой уже есть решение (например, в оригинальной статье), то вам пологается 3 балла из 10.\n",
        "\n",
        "Остальные баллы зачисляются в зависимости от того, насколько вы продвинулись в решении той задачи, которую вы предложили. \n",
        "\n",
        "Как определить, что задача оригинальная? Понятно, что все источники мы не сможем проверить, так что не будем снимать баллы, если такую же задачу кто-то когда-то решал. Но зато будем проверять код на оригинальность. А именно, пользоваться чужим кодом в принципе не запрещено. Но оригинальность самой работы (в том числе и по части кода) должна быть существенной. Совсем будет хорошо, если вы укажете источник, из которого берется часть кода. \n",
        "Кодом ДЛС можно пользоваться без ограничений.\n",
        "\n",
        "Процесс поиска не решённой задачи может выглядеть примерно так:\n",
        "\n",
        "- Хмм, а что если красить карту мира в разные цвета?\n",
        "\\*\\*гуглит\\*\\* А, это решили уже.\n",
        "\n",
        "- Хммм, а что если фотки черно белые разрисовывать? \\*\\*гуглит\\*\\* Это решили уже\n",
        "\n",
        "- А что если бурых медведей в белых и наоборот? \\*\\*гуглит\\*\\* Вроде никто пока такого не делал.\n",
        "\n",
        "Выбираем и решаем эту задачу\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCqoOhB4xsT2"
      },
      "source": [
        "\r\n",
        "# load, split and scale the maps dataset ready for training\r\n",
        "from os import listdir\r\n",
        "from numpy import asarray\r\n",
        "from numpy import vstack\r\n",
        "from keras.preprocessing.image import img_to_array\r\n",
        "from keras.preprocessing.image import load_img\r\n",
        "from numpy import savez_compressed\r\n",
        " \r\n",
        "# load all images in a directory into memory\r\n",
        "def load_images(path, size=(256,512)):\r\n",
        "\tsrc_list, tar_list = list(), list()\r\n",
        "\t# enumerate filenames in directory, assume all are images\r\n",
        "\tfor filename in listdir(path):\r\n",
        "\t\t# load and resize the image\r\n",
        "\t\tpixels = load_img(path + filename, target_size=size)\r\n",
        "\t\t# convert to numpy array\r\n",
        "\t\tpixels = img_to_array(pixels)\r\n",
        "\t\t# split into satellite and map\r\n",
        "\t\tsat_img, map_img = pixels[:, :256], pixels[:, 256:]\r\n",
        "\t\tsrc_list.append(sat_img)\r\n",
        "\t\ttar_list.append(map_img)\r\n",
        "\treturn [asarray(src_list), asarray(tar_list)]\r\n",
        " \r\n",
        "# dataset path\r\n",
        "path = '/content/maps/train/'\r\n",
        "# load dataset\r\n",
        "[src_images, tar_images] = load_images(path)\r\n",
        "print('Loaded: ', src_images.shape, tar_images.shape)\r\n",
        "# save as compressed numpy array\r\n",
        "filename = 'maps_256.npz'\r\n",
        "savez_compressed(filename, src_images, tar_images)\r\n",
        "print('Saved dataset: ', filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JaTrNtb3QKM"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from torchvision import models\r\n",
        "import torch.optim as optim\r\n",
        "from time import time\r\n",
        "\r\n",
        "from matplotlib import rcParams"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9IaVy_76W_s"
      },
      "source": [
        "# define the discriminator model\r\n",
        "class define_discriminator(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        # encoder (downsampling)\r\n",
        "        self.enc_conv0 = nn.Sequential(nn.Conv2d(3, 64, kernel_size=3, padding=1), \r\n",
        "                                       nn.BatchNorm2d(64),\r\n",
        "                                       nn.ReLU(), \r\n",
        "                                       nn.Conv2d(64, 64, kernel_size=3, padding=1),\r\n",
        "                                       nn.BatchNorm2d(64),\r\n",
        "                                       nn.ReLU())\r\n",
        "        self.pool0 = nn.MaxPool2d(kernel_size=2, stride=2)\r\n",
        "\r\n",
        "        self.enc_conv1 = nn.Sequential(nn.Conv2d(64, 128, kernel_size=3, padding=1), \r\n",
        "                                       nn.BatchNorm2d(128),\r\n",
        "                                       nn.ReLU(), \r\n",
        "                                       nn.Conv2d(128, 128, kernel_size=3, padding=1),\r\n",
        "                                       nn.BatchNorm2d(128),\r\n",
        "                                       nn.ReLU())\r\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\r\n",
        "        \r\n",
        "        self.enc_conv2 = nn.Sequential(nn.Conv2d(128, 256, kernel_size=3, padding=1), \r\n",
        "                                       nn.BatchNorm2d(256),\r\n",
        "                                       nn.ReLU(), \r\n",
        "                                       nn.Conv2d(256, 256, kernel_size=3, padding=1),\r\n",
        "                                       nn.BatchNorm2d(256),\r\n",
        "                                       nn.ReLU())\r\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\r\n",
        "\r\n",
        "        self.enc_conv3 = nn.Sequential(nn.Conv2d(256, 512, kernel_size=3, padding=1), \r\n",
        "                                       nn.BatchNorm2d(512),\r\n",
        "                                       nn.ReLU(), \r\n",
        "                                       nn.Conv2d(512, 512, kernel_size=3, padding=1),\r\n",
        "                                       nn.BatchNorm2d(512),\r\n",
        "                                       nn.ReLU())\r\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\r\n",
        "\r\n",
        "        # bottleneck\r\n",
        "        self.bottleneck_conv = nn.Sequential(nn.Conv2d(512, 1024, kernel_size=3, padding=1), \r\n",
        "                                       nn.BatchNorm2d(1024),\r\n",
        "                                       nn.ReLU(), \r\n",
        "                                       nn.Conv2d(1024, 1024, kernel_size=3, padding=1),\r\n",
        "                                       nn.BatchNorm2d(1024),\r\n",
        "                                       nn.ReLU())\r\n",
        "\r\n",
        "        # decoder (upsampling)\r\n",
        "        self.upsample0 = nn.UpsamplingNearest2d(scale_factor=2)\r\n",
        "        self.dec_conv0 = nn.Sequential(nn.Conv2d(1024 + 512, 1024, kernel_size=3, padding=1), \r\n",
        "                                       nn.BatchNorm2d(1024),\r\n",
        "                                       nn.ReLU(), \r\n",
        "                                       nn.Conv2d(1024, 512, kernel_size=3, padding=1),\r\n",
        "                                       nn.BatchNorm2d(512),\r\n",
        "                                       nn.ReLU())\r\n",
        "        self.upsample1 = nn.UpsamplingNearest2d(scale_factor=2)\r\n",
        "        self.dec_conv1 = nn.Sequential(nn.Conv2d(512 + 256, 256, kernel_size=3, padding=1), \r\n",
        "                                       nn.BatchNorm2d(256),\r\n",
        "                                       nn.ReLU(), \r\n",
        "                                       nn.Conv2d(256, 256, kernel_size=3, padding=1),\r\n",
        "                                       nn.BatchNorm2d(256),\r\n",
        "                                       nn.ReLU())\r\n",
        "        self.upsample2 = nn.UpsamplingNearest2d(scale_factor=2)\r\n",
        "        self.dec_conv2 = nn.Sequential(nn.Conv2d(256 + 128, 128, kernel_size=3, padding=1), \r\n",
        "                                       nn.BatchNorm2d(128),\r\n",
        "                                       nn.ReLU(), \r\n",
        "                                       nn.Conv2d(128, 128, kernel_size=3, padding=1),\r\n",
        "                                       nn.BatchNorm2d(128),\r\n",
        "                                       nn.ReLU())\r\n",
        "        self.upsample3 = nn.UpsamplingNearest2d(scale_factor=2)\r\n",
        "        self.dec_conv3 = nn.Sequential(nn.Conv2d(128 + 64, 64, kernel_size=3, padding=1), \r\n",
        "                                       nn.BatchNorm2d(64),\r\n",
        "                                       nn.ReLU(), \r\n",
        "                                       nn.Conv2d(64, 64, kernel_size=3, padding=1),\r\n",
        "                                       nn.BatchNorm2d(64),\r\n",
        "                                       nn.ReLU(),\r\n",
        "                                       nn.Conv2d(64, 1, kernel_size=1))\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        # encoder\r\n",
        "        e0 = self.enc_conv0(x)\r\n",
        "        p0 = self.pool0(e0)\r\n",
        "        e1 = self.enc_conv1(p0)\r\n",
        "        p1 = self.pool1(e1)\r\n",
        "        e2 = self.enc_conv2(p1)\r\n",
        "        p2 = self.pool2(e2)\r\n",
        "        e3 = self.enc_conv3(p2)\r\n",
        "        p3 = self.pool3(e3)\r\n",
        "\r\n",
        "        # bottleneck\r\n",
        "        b = self.bottleneck_conv(p3)\r\n",
        "\r\n",
        "        # decoder\r\n",
        "        up0 = self.upsample0(b)\r\n",
        "        x = torch.cat([up0, e3], dim=1)\r\n",
        "        d0 = self.dec_conv0(x)\r\n",
        "\r\n",
        "        up1 = self.upsample1(d0)\r\n",
        "        x = torch.cat([up1, e2], dim=1)\r\n",
        "        d1 = self.dec_conv1(x)\r\n",
        "\r\n",
        "        up2 = self.upsample2(d1)\r\n",
        "        x = torch.cat([up2, e1], dim=1)\r\n",
        "        d2 = self.dec_conv2(x)\r\n",
        "\r\n",
        "        up3 = self.upsample3(d2)\r\n",
        "        x = torch.cat([up3, e0], dim=1)\r\n",
        "        d3 = self.dec_conv3(x)\r\n",
        "        \r\n",
        "        return d3\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tOTkKzK7Ckd"
      },
      "source": [
        "class define_generator(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        # encoder (downsampling)\r\n",
        "        self.enc_conv0 = nn.Sequential(nn.Conv2d(3, 64, kernel_size=3, padding=1), \r\n",
        "                                       nn.BatchNorm2d(64),\r\n",
        "                                       nn.ReLU(), \r\n",
        "                                       nn.Conv2d(64, 64, kernel_size=3, padding=1),\r\n",
        "                                       nn.BatchNorm2d(64),\r\n",
        "                                       nn.ReLU())\r\n",
        "        self.pool0 = nn.MaxPool2d(kernel_size=2, stride=2)\r\n",
        "\r\n",
        "        self.enc_conv1 = nn.Sequential(nn.Conv2d(64, 128, kernel_size=3, padding=1), \r\n",
        "                                       nn.BatchNorm2d(128),\r\n",
        "                                       nn.ReLU(), \r\n",
        "                                       nn.Conv2d(128, 128, kernel_size=3, padding=1),\r\n",
        "                                       nn.BatchNorm2d(128),\r\n",
        "                                       nn.ReLU())\r\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\r\n",
        "        \r\n",
        "        self.enc_conv2 = nn.Sequential(nn.Conv2d(128, 256, kernel_size=3, padding=1), \r\n",
        "                                       nn.BatchNorm2d(256),\r\n",
        "                                       nn.ReLU(), \r\n",
        "                                       nn.Conv2d(256, 256, kernel_size=3, padding=1),\r\n",
        "                                       nn.BatchNorm2d(256),\r\n",
        "                                       nn.ReLU())\r\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\r\n",
        "\r\n",
        "        self.enc_conv3 = nn.Sequential(nn.Conv2d(256, 512, kernel_size=3, padding=1), \r\n",
        "                                       nn.BatchNorm2d(512),\r\n",
        "                                       nn.ReLU(), \r\n",
        "                                       nn.Conv2d(512, 512, kernel_size=3, padding=1),\r\n",
        "                                       nn.BatchNorm2d(512),\r\n",
        "                                       nn.ReLU())\r\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\r\n",
        "\r\n",
        "        # bottleneck\r\n",
        "        self.bottleneck_conv = nn.Sequential(nn.Conv2d(512, 1024, kernel_size=3, padding=1), \r\n",
        "                                       nn.BatchNorm2d(1024),\r\n",
        "                                       nn.ReLU(), \r\n",
        "                                       nn.Conv2d(1024, 1024, kernel_size=3, padding=1),\r\n",
        "                                       nn.BatchNorm2d(1024),\r\n",
        "                                       nn.ReLU())\r\n",
        "\r\n",
        "        # decoder (upsampling)\r\n",
        "        self.upsample0 = nn.UpsamplingNearest2d(scale_factor=2)\r\n",
        "        self.dec_conv0 = nn.Sequential(nn.Conv2d(1024 + 512, 1024, kernel_size=3, padding=1), \r\n",
        "                                       nn.BatchNorm2d(1024),\r\n",
        "                                       nn.ReLU(), \r\n",
        "                                       nn.Conv2d(1024, 512, kernel_size=3, padding=1),\r\n",
        "                                       nn.BatchNorm2d(512),\r\n",
        "                                       nn.ReLU())\r\n",
        "        self.upsample1 = nn.UpsamplingNearest2d(scale_factor=2)\r\n",
        "        self.dec_conv1 = nn.Sequential(nn.Conv2d(512 + 256, 256, kernel_size=3, padding=1), \r\n",
        "                                       nn.BatchNorm2d(256),\r\n",
        "                                       nn.ReLU(), \r\n",
        "                                       nn.Conv2d(256, 256, kernel_size=3, padding=1),\r\n",
        "                                       nn.BatchNorm2d(256),\r\n",
        "                                       nn.ReLU())\r\n",
        "        self.upsample2 = nn.UpsamplingNearest2d(scale_factor=2)\r\n",
        "        self.dec_conv2 = nn.Sequential(nn.Conv2d(256 + 128, 128, kernel_size=3, padding=1), \r\n",
        "                                       nn.BatchNorm2d(128),\r\n",
        "                                       nn.ReLU(), \r\n",
        "                                       nn.Conv2d(128, 128, kernel_size=3, padding=1),\r\n",
        "                                       nn.BatchNorm2d(128),\r\n",
        "                                       nn.ReLU())\r\n",
        "        self.upsample3 = nn.UpsamplingNearest2d(scale_factor=2)\r\n",
        "        self.dec_conv3 = nn.Sequential(nn.Conv2d(128 + 64, 64, kernel_size=3, padding=1), \r\n",
        "                                       nn.BatchNorm2d(64),\r\n",
        "                                       nn.ReLU(), \r\n",
        "                                       nn.Conv2d(64, 64, kernel_size=3, padding=1),\r\n",
        "                                       nn.BatchNorm2d(64),\r\n",
        "                                       nn.ReLU(),\r\n",
        "                                       nn.Conv2d(64, 1, kernel_size=1))\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        # encoder\r\n",
        "        e0 = self.enc_conv0(x)\r\n",
        "        p0 = self.pool0(e0)\r\n",
        "        e1 = self.enc_conv1(p0)\r\n",
        "        p1 = self.pool1(e1)\r\n",
        "        e2 = self.enc_conv2(p1)\r\n",
        "        p2 = self.pool2(e2)\r\n",
        "        e3 = self.enc_conv3(p2)\r\n",
        "        p3 = self.pool3(e3)\r\n",
        "\r\n",
        "        # bottleneck\r\n",
        "        b = self.bottleneck_conv(p3)\r\n",
        "\r\n",
        "        # decoder\r\n",
        "        up0 = self.upsample0(b)\r\n",
        "        x = torch.cat([up0, e3], dim=1)\r\n",
        "        d0 = self.dec_conv0(x)\r\n",
        "\r\n",
        "        up1 = self.upsample1(d0)\r\n",
        "        x = torch.cat([up1, e2], dim=1)\r\n",
        "        d1 = self.dec_conv1(x)\r\n",
        "\r\n",
        "        up2 = self.upsample2(d1)\r\n",
        "        x = torch.cat([up2, e1], dim=1)\r\n",
        "        d2 = self.dec_conv2(x)\r\n",
        "\r\n",
        "        up3 = self.upsample3(d2)\r\n",
        "        x = torch.cat([up3, e0], dim=1)\r\n",
        "        d3 = self.dec_conv3(x)\r\n",
        "        \r\n",
        "        return d3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fXcmrO27Tec"
      },
      "source": [
        "def define_gan(g_model, d_model, image_shape):\r\n",
        "\t# make weights in the discriminator not trainable\r\n",
        "\td_model.trainable = False\r\n",
        "\t# define the source image\r\n",
        "\tin_src = Input(shape=image_shape)\r\n",
        "\t# connect the source image to the generator input\r\n",
        "\tgen_out = g_model(in_src)\r\n",
        "\t# connect the source input and generator output to the discriminator input\r\n",
        "\tdis_out = d_model([in_src, gen_out])\r\n",
        "\t# src image as input, generated image and classification output\r\n",
        "\tmodel = Model(in_src, [dis_out, gen_out])\r\n",
        "\t# compile model\r\n",
        "\topt = optim.Adam(unet_model.parameters(), lr=0.0002)\r\n",
        "\tmodel.compile(loss=['binary_crossentropy', 'mae'], optimizer=opt, loss_weights=[1,100])\r\n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}